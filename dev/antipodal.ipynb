{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating and Visualizing Antipodal Grasps on Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import trimesh\n",
    "from typing import List \n",
    "from IPython.display import clear_output\n",
    "from pydrake.all import (\n",
    "    AddMultibodyPlantSceneGraph,\n",
    "    Concatenate,\n",
    "    DiagramBuilder,\n",
    "    MeshcatVisualizer,\n",
    "    MeshcatVisualizerParams,\n",
    "    Parser,\n",
    "    PointCloud,\n",
    "    RigidTransform,\n",
    "    StartMeshcat,\n",
    "    UniformlyRandomRotationMatrix,\n",
    "    Context,\n",
    "    Diagram,\n",
    "    PointCloud\n",
    ")\n",
    "from pydrake.geometry import Meshcat\n",
    "\n",
    "from manipulation import running_as_notebook\n",
    "from manipulation.scenarios import AddFloatingRpyJoint, AddRgbdSensors, ycb\n",
    "from manipulation.utils import ConfigureParser\n",
    "from manipulation.clutter import GraspCandidateCost, GenerateAntipodalGraspCandidate\n",
    "from manipulation.icp import IterativeClosestPoint\n",
    "\n",
    "# Own utils\n",
    "from hwstation.utils import setup_builder, plot_and_simulate\n",
    "from hwstation.add_objects import get_library_scenario_data, get_library_scenario_data_without_robot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting Meshcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:drake:Meshcat listening for connections at http://localhost:7006\n"
     ]
    }
   ],
   "source": [
    "# Start meshcat\n",
    "try:\n",
    "    meshcat = Meshcat(7006)\n",
    "except:\n",
    "    pass #This error appears if this cell is executed twice (port 7006 is already taken then)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pointcloud Related Functions (to be used when finding point cloud to do grasp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_pointclouds(diagram_context: Context, diagram: Diagram):\n",
    "    point_cloud_dict = {}\n",
    "    for idx in range(4):\n",
    "        point_cloud_dict[f\"table_camera_{idx}_ptcloud\"] = diagram.GetOutputPort(f\"table_camera_{idx}_ptcloud\").Eval(diagram_context)\n",
    "    return point_cloud_dict\n",
    "\n",
    "\n",
    "def merge_point_clouds(table_pointclouds: dict, \n",
    "                        downsample_factor: float = 0.005,\n",
    "                        lower_xyz: List[float] = [0.0, -0.2, 0.5564], \n",
    "                        upper_xyz: List[float] = [1.5, 1.5, 0.8]):\n",
    "    pcd = []\n",
    "    for key in table_pointclouds.keys():\n",
    "        cloud = table_pointclouds[key]\n",
    "        pcd.append(\n",
    "            cloud.Crop(lower_xyz=lower_xyz, upper_xyz=upper_xyz)\n",
    "            )\n",
    "    merged_pcd = Concatenate(pcd)\n",
    "    down_sampled_pcd = merged_pcd.VoxelizedDownSample(voxel_size=0.005)\n",
    "    return down_sampled_pcd\n",
    "\n",
    "def get_merged_pointcloud(diagram_context: Context, diagram: Diagram):\n",
    "    \n",
    "    #Get merged point cloud from all cameras:\n",
    "    table_pointclouds = get_table_pointclouds(diagram_context, diagram)\n",
    "    merged_pcd = merge_point_clouds(table_pointclouds)\n",
    "\n",
    "    #Ensure that all number are finite:\n",
    "    merged_pcd_np = merged_pcd.xyzs().transpose()\n",
    "    mask_points = (merged_pcd_np== np.inf).all(axis=1)\n",
    "    if mask_points.any():\n",
    "        sys.exit(\"No infinite points were expected\")\n",
    "    return merged_pcd\n",
    "\n",
    "def convert_obj_to_pc(filename: str, n_samples: int = 10000, show: bool =False) -> np.ndarray:\n",
    "    book_mesh = trimesh.load(filename)\n",
    "    book_hull = book_mesh.convex_hull\n",
    "    sample_points = book_hull.sample(n_samples)\n",
    "    point_cloud = trimesh.points.PointCloud(sample_points)\n",
    "    if show:\n",
    "        scene = trimesh.Scene([book_hull, point_cloud])\n",
    "        scene.show()\n",
    "    return np.array(point_cloud.vertices).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make environment and return the diagram and context\n",
    "def make_environment_model():\n",
    "\n",
    "    # Get string describing scenario\n",
    "    scenario_data = get_library_scenario_data()\n",
    "\n",
    "    #Setting up all drake simulation objects:\n",
    "    builder, plant, scene_graph, station, parser, scenario = setup_builder(meshcat, scenario_data=scenario_data)\n",
    "\n",
    "    # Allowing the Parser to access all of the aspects in the environment including the robot (iiwa)\n",
    "    parser.AddModelsFromUrl(\"file:///workspaces/RobotLibrarian/hwstation/objects/library_setup.dmd.yaml\")\n",
    "\n",
    "    #Simulate environment (right now, only the books fall on the table)\n",
    "    diagram, plant_context, simulator = plot_and_simulate(meshcat, builder, plant, station, time_end=0.0)\n",
    "\n",
    "    context = diagram.CreateDefaultContext()\n",
    "\n",
    "    return diagram, context, plant\n",
    "\n",
    "# Another diagram for the objects the robot \"knows about\": shelves, table, cameras, books (only one for now), and a gripper.  Think of this as the model in the robot's head.\n",
    "def make_internal_model():\n",
    "    # Get string describing scenario\n",
    "    scenario_data = get_library_scenario_data_without_robot()\n",
    "\n",
    "    #Setting up all drake simulation objects:\n",
    "    builder, plant, scene_graph, station, parser, scenario = setup_builder(meshcat, scenario_data=scenario_data)\n",
    "\n",
    "    # This parser has all items in the environment except the robot and instead has a \"floating\" gripper to try and find antipodal grasps with\n",
    "    parser.AddModelsFromUrl(\"file:///workspaces/RobotLibrarian/hwstation/objects/library_setup_floating_gripper.dmd.yaml\")\n",
    "    plant.Finalize()\n",
    "    return builder.Build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding and Visualizing the Gripper Grasp Poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixing improper rotation\n"
     ]
    }
   ],
   "source": [
    "# Function just to draw the gripper at the pose that was found\n",
    "def draw_grasp_candidate(X_G, prefix=\"gripper\", draw_frames=True):\n",
    "    builder = DiagramBuilder()\n",
    "    plant, scene_graph = AddMultibodyPlantSceneGraph(builder, time_step=0.001)\n",
    "    parser = Parser(plant)\n",
    "    ConfigureParser(parser)\n",
    "    parser.AddModelsFromUrl(\n",
    "        \"package://manipulation/schunk_wsg_50_welded_fingers.sdf\"\n",
    "    )\n",
    "    plant.WeldFrames(plant.world_frame(), plant.GetFrameByName(\"body\"), X_G)\n",
    "    plant.Finalize()\n",
    "\n",
    "    # frames_to_draw = {\"gripper\": {\"body\"}} if draw_frames else {}\n",
    "    params = MeshcatVisualizerParams()\n",
    "    params.prefix = prefix\n",
    "    params.delete_prefix_on_initialization_event = False\n",
    "    visualizer = MeshcatVisualizer.AddToBuilder(\n",
    "        builder, scene_graph, meshcat, params\n",
    "    )\n",
    "    diagram = builder.Build()\n",
    "    context = diagram.CreateDefaultContext()\n",
    "    diagram.ForcedPublish(context)\n",
    " \n",
    "\n",
    "# The main process for finding the grasp poses and visualizing them\n",
    "def sample_grasps_example():\n",
    "    meshcat.Delete()\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    # Generating the environment we are working in\n",
    "    environment, environment_context, environment_plant = make_environment_model()\n",
    "\n",
    "    # Generating the internal model we will be working with to find grasp poses\n",
    "    internal_model = make_internal_model()\n",
    "    internal_model_context = internal_model.CreateDefaultContext()\n",
    "\n",
    "    # Finally a model for the visualization of grasp poses itself.\n",
    "    # Get string describing scenario\n",
    "    scenario_data = get_library_scenario_data()\n",
    "\n",
    "    #Setting up all drake simulation objects:\n",
    "    builder, plant, scene_graph, station, parser, scenario = setup_builder(meshcat, scenario_data=scenario_data)\n",
    "\n",
    "    plant.Finalize()\n",
    "\n",
    "    # Code from the grasp_selection Drake notebook\n",
    "    params = MeshcatVisualizerParams()\n",
    "    params.prefix = \"planning\"\n",
    "    visualizer = MeshcatVisualizer.AddToBuilder(\n",
    "        builder, scene_graph, meshcat, params\n",
    "    )\n",
    "    diagram = builder.Build()\n",
    "    context = diagram.CreateDefaultContext()\n",
    "    diagram.ForcedPublish(context)\n",
    "\n",
    "    # Hide the planning gripper\n",
    "    meshcat.SetProperty(\"planning/gripper\", \"visible\", False)\n",
    "\n",
    "    # Point clouds to obtain the cloud we will work with for grasps:\n",
    "    scene_pcl = get_merged_pointcloud(internal_model_context, internal_model)\n",
    "    meshcat.SetObject(\"merged_cropped_pcl\", cloud=scene_pcl, point_size=0.004)\n",
    "\n",
    "    book_filename = \"hwstation/objects/book.obj\"\n",
    "    model_pcl = convert_obj_to_pc(book_filename, show=False)\n",
    "\n",
    "    height_table = 0.5\n",
    "    initial_guess = RigidTransform(p=[0.0,0.0,height_table])\n",
    "\n",
    "    X_MS_hat, chat = IterativeClosestPoint(\n",
    "        p_Om=model_pcl,\n",
    "        p_Ws=scene_pcl.xyzs(),\n",
    "        X_Ohat=initial_guess,\n",
    "        meshcat=meshcat,\n",
    "        meshcat_scene_path=\"icp\",\n",
    "        max_iterations=25,\n",
    "    )\n",
    "\n",
    "    transformed_model_pcl = X_MS_hat @ model_pcl\n",
    "\n",
    "    cloud = PointCloud(transformed_model_pcl.shape[1])\n",
    "    cloud.mutable_xyzs()[:] = transformed_model_pcl\n",
    "    cloud.EstimateNormals(radius=0.5, num_closest=50)\n",
    "\n",
    "    meshcat.SetObject(\"planning/cloud\", cloud, point_size=0.003)\n",
    "\n",
    "    plant.GetMyContextFromRoot(context)\n",
    "    scene_graph.GetMyContextFromRoot(context)\n",
    "\n",
    "    # Now find grasp poses\n",
    "    # X_Gs will have the poses to be used for planning when working on that step\n",
    "    costs = []\n",
    "    X_Gs = []\n",
    "    for i in range(100 if running_as_notebook else 2):\n",
    "        cost, X_G = GenerateAntipodalGraspCandidate(\n",
    "            internal_model, internal_model_context, cloud, rng\n",
    "        )\n",
    "        if np.isfinite(cost):\n",
    "            costs.append(cost)\n",
    "            X_Gs.append(X_G)\n",
    "\n",
    "    indices = np.asarray(costs).argsort()[:5]\n",
    "    min_cost_XGs = []\n",
    "    for idx in indices:\n",
    "        min_cost_XGs.append(X_Gs[idx])\n",
    "\n",
    "    #Get the antipodal grasp that is closest to the robot WSG frame:\n",
    "    positions = np.stack([frame.translation() for frame in min_cost_XGs])\n",
    "\n",
    "    plant_context = environment_plant.CreateDefaultContext()\n",
    "\n",
    "    wsg = environment_plant.GetBodyByName(\"body\")\n",
    "    wsg_body_index = wsg.index()\n",
    "\n",
    "    wsg_pose = environment_plant.EvalBodyPoseInWorld(plant_context,wsg)\n",
    "    wsg_pos = wsg_pose.translation()\n",
    "\n",
    "    best_grasp_idx = np.argmin(((positions-wsg_pos)**2).sum(axis=1))\n",
    "    X_G_optim = min_cost_XGs[best_grasp_idx]\n",
    "\n",
    "    #for rank, index in enumerate(indices):\n",
    "    draw_grasp_candidate(\n",
    "        X_G_optim, prefix=f\"best grasp\", draw_frames=False\n",
    "    )\n",
    "\n",
    "    return X_G_optim\n",
    "\n",
    "\n",
    "optim_frame = sample_grasps_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
